{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T02:40:17.401068Z",
     "iopub.status.busy": "2020-09-28T02:40:17.400834Z",
     "iopub.status.idle": "2020-09-28T02:40:17.471383Z",
     "shell.execute_reply": "2020-09-28T02:40:17.470221Z",
     "shell.execute_reply.started": "2020-09-28T02:40:17.401040Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T02:40:19.063115Z",
     "iopub.status.busy": "2020-09-28T02:40:19.062889Z",
     "iopub.status.idle": "2020-09-28T02:40:19.100274Z",
     "shell.execute_reply": "2020-09-28T02:40:19.099401Z",
     "shell.execute_reply.started": "2020-09-28T02:40:19.063089Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import librosa\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "utils.loadenv()\n",
    "\n",
    "\n",
    "def columns():\n",
    "    feature_sizes = dict(chroma_stft=12, chroma_cqt=12, chroma_cens=12,\n",
    "                         tonnetz=6, mfcc=20, rmse=1, zcr=1,\n",
    "                         spectral_centroid=1, spectral_bandwidth=1,\n",
    "                         spectral_contrast=7, spectral_rolloff=1)\n",
    "    moments = ('mean', 'std', 'skew', 'kurtosis', 'median', 'min', 'max')\n",
    "\n",
    "    columns = []\n",
    "    for name, size in feature_sizes.items():\n",
    "        for moment in moments:\n",
    "            it = ((name, moment, '{:02d}'.format(i+1)) for i in range(size))\n",
    "            columns.extend(it)\n",
    "\n",
    "    names = ('feature', 'statistics', 'number')\n",
    "    columns = pd.MultiIndex.from_tuples(columns, names=names)\n",
    "\n",
    "    # More efficient to slice if indexes are sorted.\n",
    "    return columns.sort_values()\n",
    "\n",
    "\n",
    "def compute_features(tid):\n",
    "\n",
    "    features = pd.Series(index=columns(), dtype=np.float32, name=tid)\n",
    "\n",
    "    # Catch warnings as exceptions (audioread leaks file descriptors).\n",
    "    warnings.filterwarnings('error', module='librosa')\n",
    "\n",
    "    def feature_stats(name, values):\n",
    "        features[name, 'mean'] = np.mean(values, axis=1)\n",
    "        features[name, 'std'] = np.std(values, axis=1)\n",
    "        features[name, 'skew'] = stats.skew(values, axis=1)\n",
    "        features[name, 'kurtosis'] = stats.kurtosis(values, axis=1)\n",
    "        features[name, 'median'] = np.median(values, axis=1)\n",
    "        features[name, 'min'] = np.min(values, axis=1)\n",
    "        features[name, 'max'] = np.max(values, axis=1)\n",
    "\n",
    "    try:\n",
    "        filepath = utils.get_audio_path(os.environ.get('AUDIO_DIR'), tid)\n",
    "        x, sr = librosa.load(filepath, sr=None, mono=True)  # kaiser_fast\n",
    "\n",
    "        f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "        feature_stats('zcr', f)\n",
    "\n",
    "        cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                 n_bins=7*12, tuning=None))\n",
    "        assert cqt.shape[0] == 7 * 12\n",
    "        assert np.ceil(len(x)/512) <= cqt.shape[1] <= np.ceil(len(x)/512)+1\n",
    "\n",
    "        f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "        feature_stats('chroma_cqt', f)\n",
    "        f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "        feature_stats('chroma_cens', f)\n",
    "        f = librosa.feature.tonnetz(chroma=f)\n",
    "        feature_stats('tonnetz', f)\n",
    "\n",
    "        del cqt\n",
    "        stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "        assert stft.shape[0] == 1 + 2048 // 2\n",
    "        assert np.ceil(len(x)/512) <= stft.shape[1] <= np.ceil(len(x)/512)+1\n",
    "        del x\n",
    "\n",
    "        f = librosa.feature.chroma_stft(S=stft**2, n_chroma=12)\n",
    "        feature_stats('chroma_stft', f)\n",
    "\n",
    "        f = librosa.feature.rmse(S=stft)\n",
    "        feature_stats('rmse', f)\n",
    "\n",
    "        f = librosa.feature.spectral_centroid(S=stft)\n",
    "        feature_stats('spectral_centroid', f)\n",
    "        f = librosa.feature.spectral_bandwidth(S=stft)\n",
    "        feature_stats('spectral_bandwidth', f)\n",
    "        f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "        feature_stats('spectral_contrast', f)\n",
    "        f = librosa.feature.spectral_rolloff(S=stft)\n",
    "        feature_stats('spectral_rolloff', f)\n",
    "\n",
    "        mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "        del stft\n",
    "        f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "        feature_stats('mfcc', f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('{}: {}'.format(tid, repr(e)))\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-27T19:35:24.051456Z",
     "iopub.status.busy": "2020-09-27T19:35:24.051255Z",
     "iopub.status.idle": "2020-09-27T19:35:24.063272Z",
     "shell.execute_reply": "2020-09-27T19:35:24.062680Z",
     "shell.execute_reply.started": "2020-09-27T19:35:24.051432Z"
    }
   },
   "outputs": [],
   "source": [
    "def save(features, ndigits):\n",
    "\n",
    "    # Should be done already, just to be sure.\n",
    "    features.sort_index(axis=0, inplace=True)\n",
    "    features.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    features.to_csv('features.csv', float_format='%.{}e'.format(ndigits))\n",
    "\n",
    "\n",
    "def test(features, ndigits):\n",
    "\n",
    "    indices = features[features.isnull().any(axis=1)].index\n",
    "    if len(indices) > 0:\n",
    "        print('Failed tracks: {}'.format(', '.join(str(i) for i in indices)))\n",
    "\n",
    "    tmp = utils.load('features.csv')\n",
    "    np.testing.assert_allclose(tmp.values, features.values, rtol=10**-ndigits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = utils.load(os.path.join(os.getenv(\"META_DIR\"), 'tracks.csv'))\n",
    "features = pd.DataFrame(index=tracks.index,\n",
    "                        columns=columns(), dtype=np.float32)\n",
    "\n",
    "# More than usable CPUs to be CPU bound, not I/O bound. Beware memory.\n",
    "nb_workers = int(1.5 * len(os.sched_getaffinity(0)))\n",
    "\n",
    "# Longest is ~11,000 seconds. Limit processes to avoid memory errors.\n",
    "table = ((5000, 1), (3000, 3), (2000, 5), (1000, 10), (0, nb_workers))\n",
    "for duration, nb_workers in table:\n",
    "    print('Working with {} processes.'.format(nb_workers))\n",
    "\n",
    "    tids = tracks[tracks['track', 'duration'] >= duration].index\n",
    "    tracks.drop(tids, axis=0, inplace=True)\n",
    "\n",
    "    pool = multiprocessing.Pool(nb_workers)\n",
    "    it = pool.imap_unordered(compute_features, tids)\n",
    "\n",
    "    for i, row in enumerate(tqdm(it, total=len(tids))):\n",
    "        features.loc[row.name] = row\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            save(features, 10)\n",
    "\n",
    "save(features, 10)\n",
    "test(features, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:02:10.451484Z",
     "iopub.status.busy": "2020-10-04T17:02:10.451100Z",
     "iopub.status.idle": "2020-10-04T17:02:32.264840Z",
     "shell.execute_reply": "2020-10-04T17:02:32.264100Z",
     "shell.execute_reply.started": "2020-10-04T17:02:10.451438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "utils.loadenv('.env')\n",
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "META_DIR = os.environ.get('META_DIR')\n",
    "\n",
    "tracks = utils.load(os.path.join(META_DIR, 'tracks.csv'))\n",
    "features = utils.load(os.path.join(META_DIR, 'features.csv'))\n",
    "echonest = utils.load(os.path.join(META_DIR, 'echonest.csv'))\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:02:32.367648Z",
     "iopub.status.busy": "2020-10-04T17:02:32.367422Z",
     "iopub.status.idle": "2020-10-04T17:02:33.011755Z",
     "shell.execute_reply": "2020-10-04T17:02:33.010620Z",
     "shell.execute_reply.started": "2020-10-04T17:02:32.367623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8000, 52), (8000, 518))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "subset = tracks.index[tracks['set', 'subset'] <= 'small']\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:02:33.013791Z",
     "iopub.status.busy": "2020-10-04T17:02:33.013373Z",
     "iopub.status.idle": "2020-10-04T17:02:33.546337Z",
     "shell.execute_reply": "2020-10-04T17:02:33.545547Z",
     "shell.execute_reply.started": "2020-10-04T17:02:33.013745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples, 800 validation examples, 800 testing examples\n",
      "\n",
      "Top genres (8): ['Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Pop', 'Rock']\n",
      "\n",
      "All genres (114): [1, 2, 6, 10, 12, 15, 16, 17, 18, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 38, 41, 42, 45, 46, 47, 49, 53, 58, 64, 66, 70, 71, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 167, 171, 172, 174, 177, 180, 181, 182, 183, 184, 185, 186, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 314, 337, 359, 360, 361, 362, 400, 401, 404, 439, 440, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 695, 741, 763, 808, 811, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('\\nTop genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('\\nAll genres ({}): {}'.format(len(genres), genres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:48:36.425446Z",
     "iopub.status.busy": "2020-10-04T17:48:36.425063Z",
     "iopub.status.idle": "2020-10-04T17:48:36.433078Z",
     "shell.execute_reply": "2020-10-04T17:48:36.432360Z",
     "shell.execute_reply.started": "2020-10-04T17:48:36.425397Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler\n",
    "\n",
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "        #y = enc.fit_transform(tracks['track', 'genre_top'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    x_train = features.loc[train, columns].to_numpy()\n",
    "    x_val = features.loc[val, columns].to_numpy()\n",
    "    x_test = features.loc[test, columns].to_numpy()\n",
    "    \n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(x_train)\n",
    "    scaler.transform(x_val)\n",
    "    scaler.transform(x_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, x_train, x_val, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T18:56:43.806119Z",
     "iopub.status.busy": "2020-10-04T18:56:43.805907Z",
     "iopub.status.idle": "2020-10-04T18:56:43.821454Z",
     "shell.execute_reply": "2020-10-04T18:56:43.820787Z",
     "shell.execute_reply.started": "2020-10-04T18:56:43.806095Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "OUT_DIR = \"./outputs/\"\n",
    "MODEL_DIR = os.path.join(OUT_DIR, \"models\")\n",
    "\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \n",
    "    with open(filepath, 'wb') as fp:\n",
    "        pickle.dump(model, fp)\n",
    "\n",
    "\n",
    "def test_classifiers_features(classifiers, feature_sets, exec_id=None, multi_label=False):\n",
    "\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    \n",
    "    print(\"Classifiers: {}\\nFeature Sets: {}\".format(classifiers, feature_sets))\n",
    "    \n",
    "    if exec_id is None: exec_id = str(datetime.datetime.utcnow().isoformat())\n",
    "    execution_path = os.path.join(MODEL_DIR, exec_id)\n",
    "    os.makedirs(execution_path, exist_ok=True)\n",
    "    \n",
    "    mean_accuracies = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    precisions = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    recalls = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    f1_measures = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "\n",
    "    for fset_name, fset in tqdm(feature_sets.items(), desc='Feature sets'):\n",
    "        \n",
    "        y_train_true, y_val_true, _, x_train, x_val, _ = pre_process(tracks, features_all, fset, multi_label)\n",
    "        \n",
    "        mean_accuracies.loc[fset_name, 'dim'] = x_train.shape[1]\n",
    "        precisions.loc[fset_name, 'dim'] = x_train.shape[1]\n",
    "        recalls.loc[fset_name, 'dim'] = x_train.shape[1]\n",
    "        f1_measures.loc[fset_name, 'dim'] = x_train.shape[1]\n",
    "\n",
    "        for clf_name, clf in tqdm(classifiers.items(), desc='Classifiers', leave=False):\n",
    "            \n",
    "            # train model\n",
    "            t = time.process_time()\n",
    "            clf.fit(x_train, y_train_true)\n",
    "            \n",
    "            # run prediction on validation set\n",
    "            y_val_pred = clf.predict(x_val)\n",
    "            \n",
    "            assert y_val_true.shape == y_val_pred.shape, \"Shapes of y_val for GT and PREDICTION don't match.\"\n",
    "\n",
    "            # get metrics\n",
    "            mean_acc = clf.score(x_val, y_val_true)\n",
    "            #accuracy = accuracy_score(y_val_true, y_val_pred)\n",
    "                \n",
    "            precision = sklearn.metrics.precision_score(y_val_true, y_val_pred, average='macro')\n",
    "            recall = sklearn.metrics.recall_score(y_val_true, y_val_pred, average='macro')\n",
    "            f1 = sklearn.metrics.f1_score(y_val_true, y_val_pred, average='macro')\n",
    "            \n",
    "            # print(\"{}\\t{}\\t{}\\t{}\".format(mean_acc, precision, recall, f1))\n",
    "            \n",
    "            # update dataframes\n",
    "            mean_accuracies.loc[fset_name, clf_name] = mean_acc\n",
    "            precisions.loc[fset_name, clf_name] = precision\n",
    "            recalls.loc[fset_name, clf_name] = recall\n",
    "            f1_measures.loc[fset_name, clf_name] = f1\n",
    "\n",
    "            # ROC AUC\n",
    "            # auc = sklearn.metrics.roc_auc_score(y_val_true, y_val_pred_probs)\n",
    "            # print('ROC AUC: %f' % auc)\n",
    "            \n",
    "            # confusion matrix\n",
    "            # matrix = sklearn.metrics.confusion_matrix(y_val_true, y_val_pred)\n",
    "            # print(matrix)\n",
    "            \n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "            \n",
    "            # save model to disk\n",
    "            try:\n",
    "                filepath = os.path.join(execution_path, \"{}_{}.pkl\".format(clf_name, fset_name))\n",
    "                save_model(model=clf, filepath=filepath)\n",
    "            except Exception as err:\n",
    "                print(\"Failed to save model {} on disk: {}\".format(clf_name, err))\n",
    "\n",
    "    metrics = {\n",
    "        'acc': mean_accuracies,\n",
    "        'precision': precisions,\n",
    "        'recall': recalls,\n",
    "        'f1': f1_measures,\n",
    "    }\n",
    "            \n",
    "    return metrics, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T18:56:46.367404Z",
     "iopub.status.busy": "2020-10-04T18:56:46.367156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers: {'LR': LogisticRegression(), 'kNN': KNeighborsClassifier(n_neighbors=200), 'SVCrbf': SVC(), 'SVCpoly1': SVC(degree=1, kernel='poly'), 'linSVC1': SVC(kernel='linear'), 'linSVC2': LinearSVC(), 'DT': DecisionTreeClassifier(max_depth=5), 'RF': RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10), 'AdaBoost': AdaBoostClassifier(n_estimators=10), 'MLP1': MLPClassifier(max_iter=2000), 'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000), 'NB': GaussianNB(), 'QDA': QuadraticDiscriminantAnalysis()}\n",
      "Feature Sets: {'chroma_cens': 'chroma_cens', 'chroma_cqt': 'chroma_cqt', 'chroma_stft': 'chroma_stft', 'mfcc': 'mfcc', 'rmse': 'rmse', 'spectral_bandwidth': 'spectral_bandwidth', 'spectral_centroid': 'spectral_centroid', 'spectral_contrast': 'spectral_contrast', 'spectral_rolloff': 'spectral_rolloff', 'tonnetz': 'tonnetz', 'zcr': 'zcr', 'mfcc/contrast': ['mfcc', 'spectral_contrast'], 'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'], 'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'], 'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'], 'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'], 'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'], 'all_non-echonest': ['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse', 'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast', 'spectral_rolloff', 'tonnetz', 'zcr']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f2bea88e23461d91c54493277d9ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Feature sets', max=18.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea7b8ddb34f4c55b1c44ae500978e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Classifiers', max=13.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'LR':       LogisticRegression(),\n",
    "    'kNN':      KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf':   SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1':  SVC(kernel=\"linear\"),\n",
    "    'linSVC2':  LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT':       DecisionTreeClassifier(max_depth=5),\n",
    "    'RF':       RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1':     MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2':     MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB':       GaussianNB(),\n",
    "    'QDA':      QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "RETRAIN = True\n",
    "if RETRAIN:\n",
    "    metrics, times = test_classifiers_features(classifiers, feature_sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "OUT_DIR = \"outputs/\"\n",
    "unique_name = str(datetime.datetime.utcnow().isoformat()) + \".bin\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "with open(os.path.join(OUT_DIR, unique_name), 'wb') as fp:\n",
    "    pickle.dump(metrics, fp, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T18:55:39.681748Z",
     "iopub.status.busy": "2020-10-04T18:55:39.681358Z",
     "iopub.status.idle": "2020-10-04T18:55:39.779901Z",
     "shell.execute_reply": "2020-10-04T18:55:39.778989Z",
     "shell.execute_reply.started": "2020-10-04T18:55:39.681700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acc:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col3{\n",
       "            background-color:  green;\n",
       "        }#T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col6{\n",
       "            : ;\n",
       "            background-color:  orange;\n",
       "        }</style><table id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dim</th>        <th class=\"col_heading level0 col1\" >LR</th>        <th class=\"col_heading level0 col2\" >kNN</th>        <th class=\"col_heading level0 col3\" >SVCrbf</th>        <th class=\"col_heading level0 col4\" >linSVC1</th>        <th class=\"col_heading level0 col5\" >DT</th>        <th class=\"col_heading level0 col6\" >AdaBoost</th>        <th class=\"col_heading level0 col7\" >MLP2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col1\" class=\"data row0 col1\" >28.38%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col2\" class=\"data row0 col2\" >25.37%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col3\" class=\"data row0 col3\" >31.13%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col4\" class=\"data row0 col4\" >29.38%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col5\" class=\"data row0 col5\" >22.00%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col6\" class=\"data row0 col6\" >21.25%</td>\n",
       "                        <td id=\"T_32230d5a_0673_11eb_8d73_382c4a77d109row0_col7\" class=\"data row0 col7\" >26.38%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c94ea4b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'precision:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col3{\n",
       "            background-color:  green;\n",
       "        }#T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col5{\n",
       "            : ;\n",
       "            background-color:  orange;\n",
       "        }</style><table id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dim</th>        <th class=\"col_heading level0 col1\" >LR</th>        <th class=\"col_heading level0 col2\" >kNN</th>        <th class=\"col_heading level0 col3\" >SVCrbf</th>        <th class=\"col_heading level0 col4\" >linSVC1</th>        <th class=\"col_heading level0 col5\" >DT</th>        <th class=\"col_heading level0 col6\" >AdaBoost</th>        <th class=\"col_heading level0 col7\" >MLP2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col1\" class=\"data row0 col1\" >27.18%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col2\" class=\"data row0 col2\" >23.98%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col3\" class=\"data row0 col3\" >29.45%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col4\" class=\"data row0 col4\" >28.41%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col5\" class=\"data row0 col5\" >15.22%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col6\" class=\"data row0 col6\" >16.72%</td>\n",
       "                        <td id=\"T_32257cf2_0673_11eb_8d73_382c4a77d109row0_col7\" class=\"data row0 col7\" >26.14%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c94e0b290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'recall:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_3227b788_0673_11eb_8d73_382c4a77d109row0_col3{\n",
       "            background-color:  green;\n",
       "        }#T_3227b788_0673_11eb_8d73_382c4a77d109row0_col6{\n",
       "            : ;\n",
       "            background-color:  orange;\n",
       "        }</style><table id=\"T_3227b788_0673_11eb_8d73_382c4a77d109\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dim</th>        <th class=\"col_heading level0 col1\" >LR</th>        <th class=\"col_heading level0 col2\" >kNN</th>        <th class=\"col_heading level0 col3\" >SVCrbf</th>        <th class=\"col_heading level0 col4\" >linSVC1</th>        <th class=\"col_heading level0 col5\" >DT</th>        <th class=\"col_heading level0 col6\" >AdaBoost</th>        <th class=\"col_heading level0 col7\" >MLP2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3227b788_0673_11eb_8d73_382c4a77d109level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col1\" class=\"data row0 col1\" >28.38%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col2\" class=\"data row0 col2\" >25.38%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col3\" class=\"data row0 col3\" >31.13%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col4\" class=\"data row0 col4\" >29.38%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col5\" class=\"data row0 col5\" >22.00%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col6\" class=\"data row0 col6\" >21.25%</td>\n",
       "                        <td id=\"T_3227b788_0673_11eb_8d73_382c4a77d109row0_col7\" class=\"data row0 col7\" >26.38%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c94e16290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'f1:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col3{\n",
       "            background-color:  green;\n",
       "        }#T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col6{\n",
       "            : ;\n",
       "            background-color:  orange;\n",
       "        }</style><table id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dim</th>        <th class=\"col_heading level0 col1\" >LR</th>        <th class=\"col_heading level0 col2\" >kNN</th>        <th class=\"col_heading level0 col3\" >SVCrbf</th>        <th class=\"col_heading level0 col4\" >linSVC1</th>        <th class=\"col_heading level0 col5\" >DT</th>        <th class=\"col_heading level0 col6\" >AdaBoost</th>        <th class=\"col_heading level0 col7\" >MLP2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col1\" class=\"data row0 col1\" >27.33%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col2\" class=\"data row0 col2\" >22.71%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col3\" class=\"data row0 col3\" >29.95%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col4\" class=\"data row0 col4\" >28.55%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col5\" class=\"data row0 col5\" >17.65%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col6\" class=\"data row0 col6\" >17.18%</td>\n",
       "                        <td id=\"T_322c05a4_0673_11eb_8d73_382c4a77d109row0_col7\" class=\"data row0 col7\" >26.12%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c94e5cbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'times:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >LR</th>        <th class=\"col_heading level0 col1\" >kNN</th>        <th class=\"col_heading level0 col2\" >SVCrbf</th>        <th class=\"col_heading level0 col3\" >linSVC1</th>        <th class=\"col_heading level0 col4\" >DT</th>        <th class=\"col_heading level0 col5\" >AdaBoost</th>        <th class=\"col_heading level0 col6\" >MLP2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col0\" class=\"data row0 col0\" >4.5226</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col1\" class=\"data row0 col1\" >2.1645</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col2\" class=\"data row0 col2\" >8.4531</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col3\" class=\"data row0 col3\" >17.0639</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col4\" class=\"data row0 col4\" >0.2885</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col5\" class=\"data row0 col5\" >0.6720</td>\n",
       "                        <td id=\"T_322cfaea_0673_11eb_8d73_382c4a77d109row0_col6\" class=\"data row0 col6\" >140.7717</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9c94dc84d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        is_min = s == min(s[1:])\n",
    "        max_highlight = ['background-color: green' if v else '' for v in is_max]\n",
    "        min_highlight = ['background-color: orange' if v else '' for v in is_min]\n",
    "        zipped = [ \";\".join([a, b]) for a, b in zip(max_highlight, min_highlight) ]\n",
    "        return zipped\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])\n",
    "\n",
    "\n",
    "for key, m in metrics.items():\n",
    "\n",
    "    ipd.display(\"{}:\".format(key))\n",
    "    ipd.display(format_scores(m))\n",
    "\n",
    "ipd.display(\"times:\")\n",
    "ipd.display(times.style.format('{:.4f}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T02:32:50.400555Z",
     "iopub.status.busy": "2020-09-28T02:32:50.400199Z",
     "iopub.status.idle": "2020-09-28T02:32:50.404598Z",
     "shell.execute_reply": "2020-09-28T02:32:50.403591Z",
     "shell.execute_reply.started": "2020-09-28T02:32:50.400511Z"
    }
   },
   "source": [
    "## DL on raw audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T02:45:53.746225Z",
     "iopub.status.busy": "2020-09-28T02:45:53.745995Z",
     "iopub.status.idle": "2020-09-28T02:45:53.768001Z",
     "shell.execute_reply": "2020-09-28T02:45:53.767295Z",
     "shell.execute_reply.started": "2020-09-28T02:45:53.746197Z"
    }
   },
   "source": [
    "### Select small FMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:17:33.765989Z",
     "iopub.status.busy": "2020-10-01T23:17:33.765654Z",
     "iopub.status.idle": "2020-10-01T23:17:34.336723Z",
     "shell.execute_reply": "2020-10-01T23:17:34.336065Z",
     "shell.execute_reply.started": "2020-10-01T23:17:33.765930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8000, 52), (8000, 518))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tracks.index[tracks['set', 'subset'] <= 'small']\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:17:34.338730Z",
     "iopub.status.busy": "2020-10-01T23:17:34.338392Z",
     "iopub.status.idle": "2020-10-01T23:17:34.348865Z",
     "shell.execute_reply": "2020-10-01T23:17:34.347917Z",
     "shell.execute_reply.started": "2020-10-01T23:17:34.338696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples, 800 validation examples, 800 testing examples\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:17:34.350859Z",
     "iopub.status.busy": "2020-10-01T23:17:34.350477Z",
     "iopub.status.idle": "2020-10-01T23:17:34.908662Z",
     "shell.execute_reply": "2020-10-01T23:17:34.908043Z",
     "shell.execute_reply.started": "2020-10-01T23:17:34.350804Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "labels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:17:34.911433Z",
     "iopub.status.busy": "2020-10-01T23:17:34.911104Z",
     "iopub.status.idle": "2020-10-01T23:17:35.410235Z",
     "shell.execute_reply": "2020-10-01T23:17:35.409423Z",
     "shell.execute_reply.started": "2020-10-01T23:17:34.911392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     2      5     10 ... 154413 154414 155066]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1321967)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just be sure that everything is fine. Multiprocessing is tricky to debug.\n",
    "print(train.to_numpy())\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(train, batch_size=2).__next__()[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:37:17.097437Z",
     "iopub.status.busy": "2020-10-01T23:37:17.097165Z",
     "iopub.status.idle": "2020-10-01T23:37:17.103380Z",
     "shell.execute_reply": "2020-10-01T23:37:17.102085Z",
     "shell.execute_reply.started": "2020-10-01T23:37:17.097399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keras parameters.\n",
    "import os\n",
    "\n",
    "NB_WORKER = len(os.sched_getaffinity(0))  # number of usables CPUs\n",
    "params = {'use_multiprocessing': True, 'workers': NB_WORKER, 'max_queue_size': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T02:49:22.068850Z",
     "iopub.status.busy": "2020-09-28T02:49:22.068468Z",
     "iopub.status.idle": "2020-09-28T02:49:22.169729Z",
     "shell.execute_reply": "2020-09-28T02:49:22.167798Z",
     "shell.execute_reply.started": "2020-09-28T02:49:22.068808Z"
    }
   },
   "source": [
    "### Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T23:37:23.555485Z",
     "iopub.status.busy": "2020-10-01T23:37:23.555158Z",
     "iopub.status.idle": "2020-10-01T23:37:57.723444Z",
     "shell.execute_reply": "2020-10-01T23:37:57.719046Z",
     "shell.execute_reply.started": "2020-10-01T23:37:23.555435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "Dimensionality: (59953,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   2/6400 [..............................] - ETA: 22:11:29 - loss: 159006265972607.6875 - accuracy: 0.1328"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (59929) into shape (59953)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 650, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"/home/lucas/work/ds/project/code/baseline/utils.py\", line 351, in __next__\n    self.X[i] = self.loader.load(get_audio_path(audio_dir, tid))\nValueError: could not broadcast input array from shape (59929) into shape (59953)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f6f3cbf9eb26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# fit_generator(<utils.bui..., 6400, epochs=2, workers=4, use_multiprocessing=True, max_queue_size=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (59929) into shape (59953)"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "import utils\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "loader = utils.FfmpegLoader(sampling_rate=2000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=1000, input_shape=loader.shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(units=labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size, epochs=2, **params)\n",
    "# fit_generator(<utils.bui..., 6400, epochs=2, workers=4, use_multiprocessing=True, max_queue_size=10)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)\n",
    "#Y = model.predict_generator(SampleLoader(test, batch_size=64), test.size, **params);\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-02T00:08:56.990029Z",
     "iopub.status.busy": "2020-10-02T00:08:56.989734Z",
     "iopub.status.idle": "2020-10-02T00:09:22.880655Z",
     "shell.execute_reply": "2020-10-02T00:09:22.877045Z",
     "shell.execute_reply.started": "2020-10-02T00:08:56.989989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 479625, 1)\n",
      "(None, 936, 128)\n",
      "(None, 929, 32)\n",
      "(None, 225, 32)\n",
      "(None, 56, 32)\n",
      "(None, 1792)\n",
      "(None, 100)\n",
      "(None, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 512, strides=512)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  28/6400 [..............................] - ETA: 1:32:59 - loss: 48574014952753264877031603044352.0000 - accuracy: 0.0964"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (479434) into shape (479625)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 650, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"/home/lucas/work/ds/project/code/baseline/utils.py\", line 351, in __next__\n    self.X[i] = self.loader.load(get_audio_path(audio_dir, tid))\nValueError: could not broadcast input array from shape (479434) into shape (479625)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9fcfc3297182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampleLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/lucas/Data/installed/anaconda3/envs/ds/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (479434) into shape (479625)"
     ]
    }
   ],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=16000)\n",
    "#loader = utils.LibrosaLoader(sampling_rate=16000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((-1, 1), input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D(128, 512, subsample_length=512))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=10), train.size, epochs=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=10), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=10), test.size, **params)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_ds",
   "language": "python",
   "name": "ca_ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
