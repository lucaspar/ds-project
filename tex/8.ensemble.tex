\section{Feature and Model selection}

% \kant[1-10]     % remove me

% As shown in the , the features derived from MFCC combined with SVM classifiers provide the highest accuracy so far. The numbers will be more accurate if we train them with K-fold methods if we have enough time.

% \subsubsection{Analysis}

Based on what we conclude in the PRELIMINARY RESULTS, in our ensemble method, we select the Mel-Frequency Cepstrum Coefficients and Spectral Contrast as our fixed feature sets. In terms of models, for experiementing, we create two ensembles for testing the diversity of for Ensemble members. For Ensemble One, we select the same type of the models or with good F1 performance models as our members. As for Ensemble Two, we pick classifiers that have significant diversity among the models.

Ensemble One:
\begin{itemize}
    \item LogisticRegression
    \item SVCrbf
    \item SVCpoly1 
    \item linSVC1
    \item linSVC2
\end{itemize}

Ensemble One:
\begin{itemize}
    \item MLP2
    \item SVCrbf
    \item LogisticRegression
\end{itemize}
